#
# Sample properties file for JXTandem Launcher
#
#
# may be specified on the command line as well
#params=tandem.xml
#
# If using a cluster this is the hdfs directory    if unspecified
# will run locally
# use line below to run remotely
# remoteBaseDirectory=s3n://lordjoe/VentnerEcoli/
 #remoteBaseDirectory=File:///user/howdah/JXTandem/data/<LOCAL_DIRECTORY>
#use line below to run on the cluster
#remoteBaseDirectory=/user/howdah/JXTandem/data/<LOCAL_DIRECTORY>
#
#  hdfs job tracker
remoteHost=glados
#
#  port on the job tracker
remotePort= 9000
#
#  Actual job tracker with port - not the same as name node port
remoteJobTracker= glados:9001
#
#  user on the job tracker
remoteUser=slewis
#
#  encrypted password  on the job tracker alternative is plainTextRemotePassword
#encryptedRemotePassword=aWnQ4DbdoSGivLcfi56hGKK8tx+LnqEYory3H4ueoRiivLcfi56hGA==
#
#  plain password  on the job tracker alternative is encryptedRemotePassword
#plainTextRemotePassword=secret

#
#
# Maximum number of peptides to handle ina reducer - raising this will raise the memory requirements on the cluster
# default is 1000
maxPeptideFragmentsPerReducer=50000

#
# sets mapres.max.splt.size
#  a lower number forces more mappers in my splitters which is good
# the default is 64mb but for what we are doing smaller seems to be better
# when mappers do a lot of work - this is 16 megs
#maxSplitSize=16777216
maxSplitSize=3000000

#
# MaxReduceTasks tunes the cluster - increase this number for
# bigger clusters
maxReduceTasks = 35

#
#
# delete hadoop directories after the process is finished with them
# set fo false if debugging and the intermediate data wants to be examined
deleteOutputDirectories=true
 #
 # compressed files take less space and are harder to read
# set false if you plan to manually read intermediate files
compressIntermediateFiles=true
 #
 # Maximum memory assigned to child tasks  in megabytes
 # maps to "mapred.child.java.opts", "-Xmx" + maxMamory + "m"
maxClusterMemory=3600

#
# override specific Hadoop prepoerties - save writing specific code
DEFINE_io.sort.factor=100
DEFINE_io.sort.mb=400
# don't start reducers until most mappers done
DEFINE_mapred.reduce.slowstart.completed.maps=0.5
#  number of map tasks for the database
DEFINE_org.systemsbiology.jxtandem.DesiredDatabaseMappers=64
#  number of map tasks for the spectra
DEFINE_org.systemsbiology.jxtandem.DesiredXMLInputMappers=7
